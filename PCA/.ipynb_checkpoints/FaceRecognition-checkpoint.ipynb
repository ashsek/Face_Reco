{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to perform face recognition. Face recognition means that for a\n",
    "given image you can tell the subject id. For our implmentation we will make use of the following 2 datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) https://git-disl.github.io/GTDLBench/datasets/att_face_dataset/\n",
    "\n",
    "2) http://cvit.iiit.ac.in/projects/IMFDB/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries to use later\n",
    "import matplotlib.image as img\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "import operator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to help us in classification tasks\n",
    "def Test(data_mat0, data_mat1, label_mat0, label_mat1):\n",
    "    '''\n",
    "        This function expects omega i.e projected test face and Phi i.e Signature of each face\n",
    "        and it then returns the accuracy of classfication for the test data.\n",
    "    '''\n",
    "    length = data_mat0.shape[0]\n",
    "    map_ = np.zeros((1, length))\n",
    "    \n",
    "    #To store predicted labels for the testting data\n",
    "    label_mat_new = np.zeros((1, length))\n",
    "    \n",
    "    #To store accuracy for the testing data\n",
    "    accuracy_mat = np.ones((1, length))\n",
    "\n",
    "    for i in range(0, length):\n",
    "        for j in range(0, length):\n",
    "            #Calculating eucledian distance between projected test data and signature of each face \n",
    "            map_[0, j] = distance.euclidean(data_mat1[i], data_mat0[j])\n",
    "            \n",
    "        #Assiging the label corresponding to the minimum distance \n",
    "        arg = map_.argmin()\n",
    "        label_mat_new[0, i] = label_mat0[arg]\n",
    "        if label_mat_new[0, i] != label_mat1[i]:\n",
    "            #If predicted label and actual label don't match then it is not accurate and insert 0\n",
    "            accuracy_mat[0, i] = 0\n",
    "    return 100 * np.sum(accuracy_mat) / np.size(accuracy_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(data_matrix, k, str):\n",
    "    '''\n",
    "        The function expects training data and a value k (number of selected feature vectors).\n",
    "        This function performs all the required training steps.\n",
    "    '''\n",
    "    isAlpha = False\n",
    "    number = 0\n",
    "    \n",
    "    # Generating mean-zero delta (dimensions: mn*p)\n",
    "    data_matrix_centered = data_matrix - np.mean(data_matrix, axis=0)\n",
    "    \n",
    "    #Generating covariance of mean-zero delta (dimension: p*p)\n",
    "    data_matrix_cov = np.cov(data_matrix_centered, rowvar=False)\n",
    "    \n",
    "    #Extracting EigenValue and EigenVector\n",
    "    (eigenValues, eigenVectors) = LA.eigh(data_matrix_cov)\n",
    "    idx = eigenValues.argsort()[::-1]\n",
    "    eigenValues = eigenValues[idx]\n",
    "    eigenVectors = eigenVectors[:, idx]\n",
    "    total = np.sum(eigenValues)\n",
    "\n",
    "    #Extracting best direction and k value i.e getting a feature vector having dimnesion: p*k\n",
    "    while isAlpha == False:\n",
    "        sum_eigVal = 0.0\n",
    "        for i in range(eigenValues.size):\n",
    "            sum_eigVal = sum_eigVal + eigenValues[i] / total\n",
    "            number += 1\n",
    "            if math.isclose(sum_eigVal, k) or sum_eigVal > k:\n",
    "                isAlpha = True\n",
    "                break\n",
    "\n",
    "    #projection matrix containing Eigen faces of dimension: k*mn           \n",
    "    projection_matrix = np.matrix([eigenVectors[n] for n in\n",
    "                                  range(number)]).T\n",
    "\n",
    "    #Saving the objects for future use\n",
    "    if not Path(str + '.pickle').exists():\n",
    "        with open(str + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(projection_matrix, handle,\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        print ('Error.' + ' Another file with same name already found.')\n",
    "    return projection_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data_matrix, proj_matrix, k, str):\n",
    "    \n",
    "    '''\n",
    "    This generates Projection matrix the returned matrices\n",
    "    have dimensions as k*1\n",
    "    '''\n",
    "    data_matrix_centered = data_matrix - np.mean(data_matrix, axis=0)\n",
    "    if proj_matrix is None:\n",
    "        #Call the train fucntion if no proj matrix exists\n",
    "        projection_matrix = Train(data_matrix, k, str)\n",
    "    else:\n",
    "        projection_matrix = proj_matrix\n",
    "        \n",
    "    #Convert to eigen faces\n",
    "    rd_data_matrix = np.matmul(data_matrix_centered, projection_matrix)\n",
    "    return rd_data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Data Matrix and their Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the images and storing them while maining the label structure\n",
    "imgMat = np.zeros((0, 10304))\n",
    "temp = np.arange(1, 41, 1) #We have 40 people\n",
    "\n",
    "label_matrix = np.array([[temp[i]] * 10 for i in range(temp.size)])\n",
    "label_matrix = label_matrix.flatten()\n",
    "\n",
    "#Reading greyscale images form the ATT dataset\n",
    "folder = 'ATT/'\n",
    "for j in range(1, 41):\n",
    "    direction = folder + 's' + str(j) + '/'\n",
    "    for i in range(1, 11):\n",
    "        directory = direction + str(i) + '.pgm'\n",
    "        image = img.imread(directory).T\n",
    "        imageVect = np.asmatrix(image.flatten())\n",
    "        imgMat = np.concatenate((imgMat, imageVect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the Dataset into Training and Test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data_matrix, test_data_matrix = np.split(imgMat, [int(.6 * len(imgMat))])\n",
    "# label_training, label_test = np.split(label_matrix, [int(.6 * len(label_matrix))])\n",
    "test_data_matrix = imgMat[0:400:2]\n",
    "training_data_matrix = imgMat[1:400:2]\n",
    "\n",
    "label_test = label_matrix[0:400:2]\n",
    "label_training = label_matrix[1:400:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.82, 0.84, 0.86, 0.88, 0.9, 0.92, 0.94, 0.96, 0.98]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'proj_data_mat_0.8.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ebb36e994816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'proj_data_mat_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mproj_data_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'proj_data_mat_0.8.pickle'"
     ]
    }
   ],
   "source": [
    "\n",
    "l = []\n",
    "for i in range(80,99,2):\n",
    "    l.append(i/100.0)\n",
    "    \n",
    "print(l)\n",
    "k = np.matrix([l])\n",
    "\n",
    "for o in range(k.size):\n",
    "    with open('proj_data_mat_' + str(k[0, o]) + '.pickle', 'rb') as \\\n",
    "        handle:\n",
    "        proj_data_mat = pickle.load(handle)\n",
    "    training_data_matrix_rd = PCA(training_data_matrix, proj_data_mat,\n",
    "                                   k[0, o], '')\n",
    "    test_data_matrix_rd = PCA(test_data_matrix, proj_data_mat,\n",
    "                               k[0, o], '')\n",
    "    acc_prc = Test(training_data_matrix_rd, test_data_matrix_rd,\n",
    "                       label_training, label_test)\n",
    "    print ('K: '+ str(k[0, o]) + ' Accuracy = ' + str(acc_prc) + '%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
